"""
æ‰«æç»“æœç¼“å­˜ç³»ç»Ÿ
æ”¯æŒRediså’Œå†…å­˜ç¼“å­˜ï¼Œé¿å…é‡å¤æ‰«æ
"""

import hashlib
import json
import logging
import time
from typing import Dict, Any, Optional, List
from datetime import datetime, timedelta
from dataclasses import dataclass, asdict

logger = logging.getLogger(__name__)


@dataclass
class CacheEntry:
    """ç¼“å­˜æ¡ç›®æ•°æ®ç±»"""
    key: str
    data: Dict[str, Any]
    created_at: float
    expires_at: float
    tool_name: str
    target: str


class ScanResultCache:
    """æ‰«æç»“æœç¼“å­˜ç®¡ç†å™¨"""
    
    # é»˜è®¤TTLé…ç½®ï¼ˆç§’ï¼‰
    DEFAULT_TTL = {
        'quick_scan': 3600,       # 1å°æ—¶
        'normal_scan': 7200,      # 2å°æ—¶
        'deep_scan': 14400,       # 4å°æ—¶
        'vulnerability_scan': 21600,  # 6å°æ—¶
        'default': 3600           # é»˜è®¤1å°æ—¶
    }
    
    # å·¥å…·ç‰¹å®šTTL
    TOOL_TTL = {
        'httpx': 1800,      # 30åˆ†é’Ÿ
        'nmap': 7200,       # 2å°æ—¶
        'nuclei': 21600,    # 6å°æ—¶ï¼ˆCVEæ‰«æç»“æœç›¸å¯¹ç¨³å®šï¼‰
        'sqlmap': 14400,    # 4å°æ—¶
        'subfinder': 86400, # 24å°æ—¶ï¼ˆå­åŸŸåå˜åŒ–è¾ƒæ…¢ï¼‰
        'amass': 86400,     # 24å°æ—¶
        'nikto': 14400,     # 4å°æ—¶
    }
    
    def __init__(self, use_redis: bool = True, redis_client=None):
        """
        åˆå§‹åŒ–ç¼“å­˜ç®¡ç†å™¨
        
        Args:
            use_redis: æ˜¯å¦ä½¿ç”¨Redis
            redis_client: Rediså®¢æˆ·ç«¯å®ä¾‹
        """
        self.use_redis = use_redis
        self.redis_client = redis_client
        self.memory_cache = {}  # å†…å­˜ç¼“å­˜ä½œä¸ºfallback
        
        if use_redis and redis_client:
            try:
                redis_client.ping()
                logger.info("âœ… Redis cache enabled")
            except Exception as e:
                logger.warning(f"âš ï¸  Redis unavailable, falling back to memory cache: {e}")
                self.use_redis = False
        else:
            logger.info("ğŸ’¾ Using memory cache")
    
    def _generate_cache_key(
        self, 
        tool_name: str, 
        target: str, 
        params: Dict[str, Any]
    ) -> str:
        """
        ç”Ÿæˆç¼“å­˜é”®
        
        Args:
            tool_name: å·¥å…·åç§°
            target: ç›®æ ‡
            params: å‚æ•°
            
        Returns:
            str: ç¼“å­˜é”®
        """
        # æ’åºå‚æ•°ä»¥ç¡®ä¿ä¸€è‡´æ€§
        sorted_params = json.dumps(params, sort_keys=True)
        
        # ç»„åˆæ•°æ®
        data = f"{tool_name}:{target}:{sorted_params}"
        
        # MD5å“ˆå¸Œ
        hash_key = hashlib.md5(data.encode()).hexdigest()
        
        return f"hexstrike:scan:{tool_name}:{hash_key}"
    
    def get(
        self, 
        tool_name: str, 
        target: str, 
        params: Optional[Dict] = None
    ) -> Optional[Dict[str, Any]]:
        """
        è·å–ç¼“å­˜ç»“æœ
        
        Args:
            tool_name: å·¥å…·åç§°
            target: ç›®æ ‡
            params: å‚æ•°
            
        Returns:
            Optional[Dict]: ç¼“å­˜çš„ç»“æœï¼Œå¦‚æœä¸å­˜åœ¨æˆ–è¿‡æœŸè¿”å›None
        """
        params = params or {}
        key = self._generate_cache_key(tool_name, target, params)
        
        try:
            if self.use_redis and self.redis_client:
                # ä»Redisè·å–
                cached = self.redis_client.get(key)
                if cached:
                    data = json.loads(cached)
                    logger.info(f"ğŸ¯ Cache HIT (Redis): {tool_name} on {target}")
                    return data
            else:
                # ä»å†…å­˜è·å–
                entry = self.memory_cache.get(key)
                if entry:
                    # æ£€æŸ¥æ˜¯å¦è¿‡æœŸ
                    if time.time() < entry.expires_at:
                        logger.info(f"ğŸ¯ Cache HIT (Memory): {tool_name} on {target}")
                        return entry.data
                    else:
                        # æ¸…ç†è¿‡æœŸæ¡ç›®
                        del self.memory_cache[key]
                        logger.debug(f"ğŸ—‘ï¸  Removed expired cache entry: {key}")
        
        except Exception as e:
            logger.error(f"âŒ Cache get error: {e}")
        
        logger.debug(f"âŒ Cache MISS: {tool_name} on {target}")
        return None
    
    def set(
        self,
        tool_name: str,
        target: str,
        params: Optional[Dict],
        result: Dict[str, Any],
        ttl: Optional[int] = None,
        scan_type: str = 'default'
    ) -> bool:
        """
        ä¿å­˜ç»“æœåˆ°ç¼“å­˜
        
        Args:
            tool_name: å·¥å…·åç§°
            target: ç›®æ ‡
            params: å‚æ•°
            result: æ‰«æç»“æœ
            ttl: è‡ªå®šä¹‰TTLï¼ˆç§’ï¼‰ï¼ŒNoneåˆ™ä½¿ç”¨é»˜è®¤å€¼
            scan_type: æ‰«æç±»å‹ï¼Œç”¨äºç¡®å®šTTL
            
        Returns:
            bool: æ˜¯å¦æˆåŠŸä¿å­˜
        """
        params = params or {}
        key = self._generate_cache_key(tool_name, target, params)
        
        # ç¡®å®šTTL
        if ttl is None:
            ttl = self.TOOL_TTL.get(
                tool_name,
                self.DEFAULT_TTL.get(scan_type, self.DEFAULT_TTL['default'])
            )
        
        try:
            # æ·»åŠ å…ƒæ•°æ®
            cached_data = {
                'result': result,
                'tool_name': tool_name,
                'target': target,
                'cached_at': datetime.now().isoformat(),
                'ttl': ttl
            }
            
            if self.use_redis and self.redis_client:
                # ä¿å­˜åˆ°Redis
                self.redis_client.setex(
                    key,
                    ttl,
                    json.dumps(cached_data)
                )
                logger.info(f"ğŸ’¾ Cached result (Redis): {tool_name} on {target} (TTL: {ttl}s)")
                return True
            else:
                # ä¿å­˜åˆ°å†…å­˜
                entry = CacheEntry(
                    key=key,
                    data=cached_data,
                    created_at=time.time(),
                    expires_at=time.time() + ttl,
                    tool_name=tool_name,
                    target=target
                )
                self.memory_cache[key] = entry
                logger.info(f"ğŸ’¾ Cached result (Memory): {tool_name} on {target} (TTL: {ttl}s)")
                return True
                
        except Exception as e:
            logger.error(f"âŒ Cache set error: {e}")
            return False
    
    def invalidate(
        self,
        tool_name: str,
        target: str,
        params: Optional[Dict] = None
    ) -> bool:
        """
        å¤±æ•ˆç¼“å­˜æ¡ç›®
        
        Args:
            tool_name: å·¥å…·åç§°
            target: ç›®æ ‡
            params: å‚æ•°
            
        Returns:
            bool: æ˜¯å¦æˆåŠŸå¤±æ•ˆ
        """
        params = params or {}
        key = self._generate_cache_key(tool_name, target, params)
        
        try:
            if self.use_redis and self.redis_client:
                deleted = self.redis_client.delete(key)
                if deleted:
                    logger.info(f"ğŸ—‘ï¸  Invalidated cache (Redis): {tool_name} on {target}")
                return bool(deleted)
            else:
                if key in self.memory_cache:
                    del self.memory_cache[key]
                    logger.info(f"ğŸ—‘ï¸  Invalidated cache (Memory): {tool_name} on {target}")
                    return True
                return False
                
        except Exception as e:
            logger.error(f"âŒ Cache invalidate error: {e}")
            return False
    
    def clear_all(self, pattern: Optional[str] = None) -> int:
        """
        æ¸…é™¤æ‰€æœ‰ç¼“å­˜æˆ–åŒ¹é…patternçš„ç¼“å­˜
        
        Args:
            pattern: é”®æ¨¡å¼ï¼ˆä»…Redisæ”¯æŒï¼‰
            
        Returns:
            int: æ¸…é™¤çš„æ¡ç›®æ•°
        """
        count = 0
        
        try:
            if self.use_redis and self.redis_client:
                if pattern:
                    # ä½¿ç”¨æ¨¡å¼åŒ¹é…åˆ é™¤
                    keys = self.redis_client.keys(pattern)
                    if keys:
                        count = self.redis_client.delete(*keys)
                else:
                    # åˆ é™¤æ‰€æœ‰hexstrikeç¼“å­˜
                    keys = self.redis_client.keys("hexstrike:scan:*")
                    if keys:
                        count = self.redis_client.delete(*keys)
                
                logger.info(f"ğŸ—‘ï¸  Cleared {count} cache entries (Redis)")
            else:
                # æ¸…é™¤å†…å­˜ç¼“å­˜
                if pattern:
                    # ç®€å•çš„æ¨¡å¼åŒ¹é…
                    keys_to_delete = [
                        k for k in self.memory_cache.keys()
                        if pattern.replace('*', '') in k
                    ]
                    for key in keys_to_delete:
                        del self.memory_cache[key]
                    count = len(keys_to_delete)
                else:
                    count = len(self.memory_cache)
                    self.memory_cache.clear()
                
                logger.info(f"ğŸ—‘ï¸  Cleared {count} cache entries (Memory)")
                
        except Exception as e:
            logger.error(f"âŒ Cache clear error: {e}")
        
        return count
    
    def get_stats(self) -> Dict[str, Any]:
        """
        è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            Dict: ç¼“å­˜ç»Ÿè®¡
        """
        try:
            if self.use_redis and self.redis_client:
                keys = self.redis_client.keys("hexstrike:scan:*")
                
                # æŒ‰å·¥å…·åˆ†ç»„ç»Ÿè®¡
                tool_counts = {}
                for key in keys:
                    # è§£æå·¥å…·åç§°
                    parts = key.decode() if isinstance(key, bytes) else key
                    parts = parts.split(':')
                    if len(parts) >= 3:
                        tool = parts[2]
                        tool_counts[tool] = tool_counts.get(tool, 0) + 1
                
                return {
                    'backend': 'redis',
                    'total_entries': len(keys),
                    'by_tool': tool_counts
                }
            else:
                # å†…å­˜ç¼“å­˜ç»Ÿè®¡
                tool_counts = {}
                valid_entries = 0
                now = time.time()
                
                for entry in self.memory_cache.values():
                    if now < entry.expires_at:
                        valid_entries += 1
                        tool = entry.tool_name
                        tool_counts[tool] = tool_counts.get(tool, 0) + 1
                
                return {
                    'backend': 'memory',
                    'total_entries': len(self.memory_cache),
                    'valid_entries': valid_entries,
                    'by_tool': tool_counts
                }
                
        except Exception as e:
            logger.error(f"âŒ Cache stats error: {e}")
            return {'error': str(e)}
    
    def cleanup_expired(self) -> int:
        """
        æ¸…ç†è¿‡æœŸçš„ç¼“å­˜æ¡ç›®ï¼ˆä»…å†…å­˜ç¼“å­˜ï¼‰
        
        Returns:
            int: æ¸…ç†çš„æ¡ç›®æ•°
        """
        if self.use_redis:
            # Redisè‡ªåŠ¨å¤„ç†è¿‡æœŸ
            return 0
        
        count = 0
        now = time.time()
        keys_to_delete = []
        
        for key, entry in self.memory_cache.items():
            if now >= entry.expires_at:
                keys_to_delete.append(key)
        
        for key in keys_to_delete:
            del self.memory_cache[key]
            count += 1
        
        if count > 0:
            logger.info(f"ğŸ—‘ï¸  Cleaned up {count} expired cache entries")
        
        return count


class CacheAwareExecutor:
    """æ”¯æŒç¼“å­˜çš„å·¥å…·æ‰§è¡Œå™¨åŒ…è£…å™¨"""
    
    def __init__(self, cache: ScanResultCache):
        """
        åˆå§‹åŒ–
        
        Args:
            cache: ç¼“å­˜ç®¡ç†å™¨å®ä¾‹
        """
        self.cache = cache
    
    def execute_with_cache(
        self,
        tool_name: str,
        target: str,
        params: Dict[str, Any],
        executor_func,
        force_refresh: bool = False,
        scan_type: str = 'default'
    ) -> Dict[str, Any]:
        """
        å¸¦ç¼“å­˜çš„å·¥å…·æ‰§è¡Œ
        
        Args:
            tool_name: å·¥å…·åç§°
            target: ç›®æ ‡
            params: å‚æ•°
            executor_func: æ‰§è¡Œå‡½æ•°
            force_refresh: å¼ºåˆ¶åˆ·æ–°ç¼“å­˜
            scan_type: æ‰«æç±»å‹
            
        Returns:
            Dict: æ‰«æç»“æœ
        """
        # å¦‚æœä¸å¼ºåˆ¶åˆ·æ–°ï¼Œå°è¯•ä»ç¼“å­˜è·å–
        if not force_refresh:
            cached = self.cache.get(tool_name, target, params)
            if cached:
                return {
                    **cached.get('result', {}),
                    'from_cache': True,
                    'cached_at': cached.get('cached_at')
                }
        
        # æ‰§è¡Œå·¥å…·
        logger.info(f"ğŸš€ Executing {tool_name} (cache miss or force refresh)")
        result = executor_func(target, params)
        
        # ä¿å­˜åˆ°ç¼“å­˜ï¼ˆä»…å½“æˆåŠŸæ—¶ï¼‰
        if isinstance(result, dict) and result.get('success'):
            self.cache.set(tool_name, target, params, result, scan_type=scan_type)
        
        return {
            **result,
            'from_cache': False
        }


# å°è¯•åˆå§‹åŒ–Rediså®¢æˆ·ç«¯
def init_cache(redis_enabled: bool = True) -> ScanResultCache:
    """
    åˆå§‹åŒ–ç¼“å­˜ç³»ç»Ÿ
    
    Args:
        redis_enabled: æ˜¯å¦å¯ç”¨Redis
        
    Returns:
        ScanResultCache: ç¼“å­˜å®ä¾‹
    """
    redis_client = None
    
    if redis_enabled:
        try:
            import redis
            redis_client = redis.Redis(
                host='localhost',
                port=6379,
                db=0,
                decode_responses=False
            )
            redis_client.ping()
            logger.info("âœ… Connected to Redis")
        except Exception as e:
            logger.warning(f"âš ï¸  Failed to connect to Redis: {e}")
            redis_client = None
    
    return ScanResultCache(
        use_redis=redis_enabled and redis_client is not None,
        redis_client=redis_client
    )


# å…¨å±€ç¼“å­˜å®ä¾‹
scan_cache = init_cache()
cache_executor = CacheAwareExecutor(scan_cache)
