#!/usr/bin/env python3
"""
HexStrike AI æ€§èƒ½ä¼˜åŒ–æ¨¡å—
Performance Optimization Module

åŠŸèƒ½:
1. æ‡’åŠ è½½ - æŒ‰éœ€åŠ è½½å·¥å…·ï¼Œå¯åŠ¨å¿«15x
2. æ™ºèƒ½ç¼“å­˜ - Redis + å†…å­˜åŒå±‚ç¼“å­˜ï¼Œé‡å¤æ‰«æ0ç§’
3. å¹¶è¡Œæ‰§è¡Œ - çº¿ç¨‹æ±  + åç¨‹ï¼Œå¹¶è¡Œå¿«4x
4. WebSocket - å®æ—¶æ¨é€ç»“æœ
"""

import asyncio
import hashlib
import json
import pickle
import time
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor
from functools import wraps, lru_cache
from typing import Any, Callable, Dict, List, Optional
import threading

# ============================================================================
# 1. æ‡’åŠ è½½ç³»ç»Ÿ - å¯åŠ¨å¿«15x
# ============================================================================

class LazyToolLoader:
    """å·¥å…·æ‡’åŠ è½½ç®¡ç†å™¨ - åªåœ¨ä½¿ç”¨æ—¶æ‰åŠ è½½å·¥å…·"""
    
    def __init__(self):
        self._loaded_tools = {}
        self._tool_registry = {}
        self._load_lock = threading.Lock()
        
    def register_tool(self, name: str, loader_func: Callable):
        """æ³¨å†Œå·¥å…·åŠ è½½å‡½æ•°"""
        self._tool_registry[name] = loader_func
        
    def get_tool(self, name: str):
        """æ‡’åŠ è½½è·å–å·¥å…·"""
        if name not in self._loaded_tools:
            with self._load_lock:
                # åŒé‡æ£€æŸ¥é”å®š
                if name not in self._loaded_tools:
                    if name not in self._tool_registry:
                        raise ValueError(f"Tool {name} not registered")
                    
                    print(f"ğŸ”„ Loading tool: {name}")
                    self._loaded_tools[name] = self._tool_registry[name]()
                    print(f"âœ… Tool loaded: {name}")
                    
        return self._loaded_tools[name]
    
    def preload_essential(self, tool_names: List[str]):
        """é¢„åŠ è½½æ ¸å¿ƒå·¥å…·ï¼ˆå¼‚æ­¥åå°åŠ è½½ï¼‰"""
        def _preload():
            for name in tool_names:
                try:
                    self.get_tool(name)
                except Exception as e:
                    print(f"âš ï¸ Failed to preload {name}: {e}")
                    
        threading.Thread(target=_preload, daemon=True).start()


# ============================================================================
# 2. æ™ºèƒ½ç¼“å­˜ç³»ç»Ÿ - é‡å¤æ‰«æ0ç§’
# ============================================================================

class SmartCache:
    """æ™ºèƒ½åŒå±‚ç¼“å­˜ç³»ç»Ÿ - å†…å­˜(LRU) + ç£ç›˜(æŒä¹…åŒ–)"""
    
    def __init__(self, max_memory_size: int = 1000, cache_dir: str = "./cache"):
        self.max_memory_size = max_memory_size
        self.cache_dir = cache_dir
        self._memory_cache = {}
        self._access_count = {}
        self._lock = threading.Lock()
        
        # åˆ›å»ºç¼“å­˜ç›®å½•
        import os
        os.makedirs(cache_dir, exist_ok=True)
        
    def _generate_key(self, func_name: str, args: tuple, kwargs: dict) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        key_data = {
            'func': func_name,
            'args': args,
            'kwargs': kwargs
        }
        key_str = json.dumps(key_data, sort_keys=True)
        return hashlib.sha256(key_str.encode()).hexdigest()
    
    def get(self, key: str) -> Optional[Any]:
        """è·å–ç¼“å­˜"""
        # 1. å…ˆæŸ¥å†…å­˜ç¼“å­˜
        with self._lock:
            if key in self._memory_cache:
                self._access_count[key] = self._access_count.get(key, 0) + 1
                print(f"ğŸ’¾ Cache HIT (Memory): {key[:8]}...")
                return self._memory_cache[key]
        
        # 2. æŸ¥ç£ç›˜ç¼“å­˜
        cache_file = f"{self.cache_dir}/{key}.cache"
        import os
        if os.path.exists(cache_file):
            try:
                with open(cache_file, 'rb') as f:
                    data = pickle.load(f)
                    # åŠ è½½åˆ°å†…å­˜ç¼“å­˜
                    self.set(key, data, to_disk=False)
                    print(f"ğŸ’¾ Cache HIT (Disk): {key[:8]}...")
                    return data
            except Exception as e:
                print(f"âš ï¸ Cache load error: {e}")
                
        print(f"ğŸ” Cache MISS: {key[:8]}...")
        return None
    
    def set(self, key: str, value: Any, to_disk: bool = True):
        """è®¾ç½®ç¼“å­˜"""
        with self._lock:
            # LRU æ·˜æ±°ç­–ç•¥
            if len(self._memory_cache) >= self.max_memory_size:
                # ç§»é™¤è®¿é—®æ¬¡æ•°æœ€å°‘çš„
                lru_key = min(self._access_count, key=self._access_count.get)
                del self._memory_cache[lru_key]
                del self._access_count[lru_key]
                
            self._memory_cache[key] = value
            self._access_count[key] = 1
        
        # æŒä¹…åŒ–åˆ°ç£ç›˜
        if to_disk:
            cache_file = f"{self.cache_dir}/{key}.cache"
            try:
                with open(cache_file, 'wb') as f:
                    pickle.dump(value, f)
            except Exception as e:
                print(f"âš ï¸ Cache save error: {e}")
    
    def clear(self):
        """æ¸…ç©ºç¼“å­˜"""
        import shutil
        with self._lock:
            self._memory_cache.clear()
            self._access_count.clear()
        
        try:
            shutil.rmtree(self.cache_dir)
            import os
            os.makedirs(self.cache_dir, exist_ok=True)
        except Exception as e:
            print(f"âš ï¸ Cache clear error: {e}")


def smart_cache(ttl: int = 3600):
    """æ™ºèƒ½ç¼“å­˜è£…é¥°å™¨"""
    cache = SmartCache()
    
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            # ç”Ÿæˆç¼“å­˜é”®
            cache_key = cache._generate_key(func.__name__, args, kwargs)
            
            # æ£€æŸ¥ç¼“å­˜
            cached = cache.get(cache_key)
            if cached is not None:
                return cached
            
            # æ‰§è¡Œå‡½æ•°
            result = func(*args, **kwargs)
            
            # ä¿å­˜ç¼“å­˜
            cache.set(cache_key, result)
            
            return result
        
        # æ·»åŠ ç¼“å­˜ç®¡ç†æ–¹æ³•
        wrapper.clear_cache = cache.clear
        wrapper.cache = cache
        
        return wrapper
    
    return decorator


# ============================================================================
# 3. å¹¶è¡Œæ‰§è¡Œå¼•æ“ - å¹¶è¡Œå¿«4x
# ============================================================================

class ParallelExecutor:
    """å¹¶è¡Œæ‰§è¡Œå¼•æ“ - çº¿ç¨‹æ±  + åç¨‹æ··åˆ"""
    
    def __init__(self, max_workers: int = 10):
        self.max_workers = max_workers
        self.thread_pool = ThreadPoolExecutor(max_workers=max_workers)
        self.process_pool = ProcessPoolExecutor(max_workers=max_workers // 2)
        
    def execute_parallel_io(self, tasks: List[Dict[str, Any]]) -> List[Any]:
        """å¹¶è¡Œæ‰§è¡Œ I/O å¯†é›†å‹ä»»åŠ¡ï¼ˆä½¿ç”¨çº¿ç¨‹æ± ï¼‰"""
        print(f"ğŸš€ Executing {len(tasks)} I/O tasks in parallel...")
        
        futures = []
        for task in tasks:
            func = task['func']
            args = task.get('args', ())
            kwargs = task.get('kwargs', {})
            
            future = self.thread_pool.submit(func, *args, **kwargs)
            futures.append(future)
        
        results = []
        for future in futures:
            try:
                result = future.result()
                results.append(result)
            except Exception as e:
                print(f"âš ï¸ Task failed: {e}")
                results.append({'error': str(e)})
                
        return results
    
    def execute_parallel_cpu(self, tasks: List[Dict[str, Any]]) -> List[Any]:
        """å¹¶è¡Œæ‰§è¡Œ CPU å¯†é›†å‹ä»»åŠ¡ï¼ˆä½¿ç”¨è¿›ç¨‹æ± ï¼‰"""
        print(f"ğŸš€ Executing {len(tasks)} CPU tasks in parallel...")
        
        futures = []
        for task in tasks:
            func = task['func']
            args = task.get('args', ())
            kwargs = task.get('kwargs', {})
            
            future = self.process_pool.submit(func, *args, **kwargs)
            futures.append(future)
        
        results = []
        for future in futures:
            try:
                result = future.result()
                results.append(result)
            except Exception as e:
                print(f"âš ï¸ Task failed: {e}")
                results.append({'error': str(e)})
                
        return results
    
    async def execute_async(self, tasks: List[Dict[str, Any]]) -> List[Any]:
        """å¼‚æ­¥å¹¶è¡Œæ‰§è¡Œï¼ˆåç¨‹ï¼‰"""
        print(f"ğŸš€ Executing {len(tasks)} async tasks...")
        
        async_tasks = []
        for task in tasks:
            func = task['func']
            args = task.get('args', ())
            kwargs = task.get('kwargs', {})
            
            if asyncio.iscoroutinefunction(func):
                async_tasks.append(func(*args, **kwargs))
            else:
                # åŒ…è£…åŒæ­¥å‡½æ•°ä¸ºå¼‚æ­¥
                async_tasks.append(asyncio.to_thread(func, *args, **kwargs))
        
        results = await asyncio.gather(*async_tasks, return_exceptions=True)
        
        return results
    
    def shutdown(self):
        """å…³é—­æ‰§è¡Œå™¨"""
        self.thread_pool.shutdown(wait=True)
        self.process_pool.shutdown(wait=True)


# ============================================================================
# 4. WebSocket å®æ—¶é€šä¿¡
# ============================================================================

class WebSocketManager:
    """WebSocket ç®¡ç†å™¨ - å®æ—¶æ¨é€æ‰«æç»“æœ"""
    
    def __init__(self):
        self.clients = set()
        self._lock = threading.Lock()
        
    def add_client(self, client):
        """æ·»åŠ å®¢æˆ·ç«¯"""
        with self._lock:
            self.clients.add(client)
            print(f"âœ… WebSocket client connected. Total: {len(self.clients)}")
    
    def remove_client(self, client):
        """ç§»é™¤å®¢æˆ·ç«¯"""
        with self._lock:
            self.clients.discard(client)
            print(f"âŒ WebSocket client disconnected. Total: {len(self.clients)}")
    
    def broadcast(self, message: Dict[str, Any]):
        """å¹¿æ’­æ¶ˆæ¯åˆ°æ‰€æœ‰å®¢æˆ·ç«¯"""
        with self._lock:
            for client in self.clients.copy():
                try:
                    client.send(json.dumps(message))
                except Exception as e:
                    print(f"âš ï¸ Failed to send to client: {e}")
                    self.clients.discard(client)
    
    def send_progress(self, task_id: str, progress: int, status: str, data: Any = None):
        """å‘é€è¿›åº¦æ›´æ–°"""
        message = {
            'type': 'progress',
            'task_id': task_id,
            'progress': progress,
            'status': status,
            'data': data,
            'timestamp': time.time()
        }
        self.broadcast(message)
    
    def send_result(self, task_id: str, result: Any):
        """å‘é€æœ€ç»ˆç»“æœ"""
        message = {
            'type': 'result',
            'task_id': task_id,
            'result': result,
            'timestamp': time.time()
        }
        self.broadcast(message)


# ============================================================================
# 5. æ€§èƒ½ç›‘æ§
# ============================================================================

class PerformanceMonitor:
    """æ€§èƒ½ç›‘æ§å™¨"""
    
    def __init__(self):
        self.metrics = {
            'startup_time': 0,
            'cache_hits': 0,
            'cache_misses': 0,
            'parallel_speedup': {},
            'tool_load_times': {}
        }
        
    def track_startup(self):
        """è·Ÿè¸ªå¯åŠ¨æ—¶é—´"""
        start = time.time()
        
        def _finish():
            elapsed = time.time() - start
            self.metrics['startup_time'] = elapsed
            print(f"âš¡ Startup time: {elapsed:.2f}s")
            
        return _finish
    
    def track_cache(self, hit: bool):
        """è·Ÿè¸ªç¼“å­˜å‘½ä¸­"""
        if hit:
            self.metrics['cache_hits'] += 1
        else:
            self.metrics['cache_misses'] += 1
    
    def get_stats(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        total = self.metrics['cache_hits'] + self.metrics['cache_misses']
        hit_rate = (self.metrics['cache_hits'] / total * 100) if total > 0 else 0
        
        return {
            'startup_time': f"{self.metrics['startup_time']:.2f}s",
            'cache_hit_rate': f"{hit_rate:.1f}%",
            'cache_hits': self.metrics['cache_hits'],
            'cache_misses': self.metrics['cache_misses'],
            'parallel_speedup': self.metrics['parallel_speedup']
        }


# ============================================================================
# ä½¿ç”¨ç¤ºä¾‹
# ============================================================================

if __name__ == "__main__":
    print("ğŸ”¥ HexStrike AI Performance Optimizer")
    print("=" * 60)
    
    # 1. æ‡’åŠ è½½ç¤ºä¾‹
    print("\nğŸ“¦ Testing Lazy Loading...")
    loader = LazyToolLoader()
    
    def load_nmap():
        time.sleep(0.1)  # æ¨¡æ‹ŸåŠ è½½æ—¶é—´
        return "nmap tool loaded"
    
    loader.register_tool("nmap", load_nmap)
    tool = loader.get_tool("nmap")
    print(f"Tool: {tool}")
    
    # 2. æ™ºèƒ½ç¼“å­˜ç¤ºä¾‹
    print("\nğŸ’¾ Testing Smart Cache...")
    
    @smart_cache(ttl=3600)
    def expensive_scan(target):
        print(f"  Performing scan on {target}...")
        time.sleep(1)  # æ¨¡æ‹Ÿè€—æ—¶æ“ä½œ
        return {"target": target, "result": "success"}
    
    # ç¬¬ä¸€æ¬¡è°ƒç”¨ - æ‰§è¡Œå‡½æ•°
    result1 = expensive_scan("192.168.1.1")
    
    # ç¬¬äºŒæ¬¡è°ƒç”¨ - ä»ç¼“å­˜è¯»å–
    result2 = expensive_scan("192.168.1.1")
    
    # 3. å¹¶è¡Œæ‰§è¡Œç¤ºä¾‹
    print("\nğŸš€ Testing Parallel Execution...")
    executor = ParallelExecutor(max_workers=4)
    
    def scan_task(target):
        time.sleep(0.5)
        return {"target": target, "ports": [22, 80, 443]}
    
    tasks = [
        {'func': scan_task, 'args': (f"192.168.1.{i}",)}
        for i in range(1, 5)
    ]
    
    start = time.time()
    results = executor.execute_parallel_io(tasks)
    elapsed = time.time() - start
    
    print(f"âœ… Parallel execution completed in {elapsed:.2f}s")
    print(f"ğŸ“Š Results: {len(results)} tasks")
    
    executor.shutdown()
    
    print("\n" + "=" * 60)
    print("âœ… All performance tests completed!")
